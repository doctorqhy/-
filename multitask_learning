import tensorflow as tf
import AlexNet_Mulity

NUM_CLASS = 10
BATCH_SIZE = 25
TFRECORD_DIR = 'D:\pycharm\PyCharm Community Edition 2017.2.3\TensorFlow\CodeDemo\captcha\\train.tfrecords'


x = tf.placeholder(tf.float32,[None,224,224])
y0 = tf.placeholder(tf.float32,[None])
y1 = tf.placeholder(tf.float32,[None])
y2 = tf.placeholder(tf.float32,[None])
y3 = tf.placeholder(tf.float32,[None])


def read_and_decode(filename):

    #读取tfrecords文件要使用队列方式读取
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TFRecordReader()
    _,serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example,
        features={
            'image_data':tf.FixedLenFeature([],tf.string),
            'label0':tf.FixedLenFeature([],tf.int64),
            'label1':tf.FixedLenFeature([],tf.int64),
            'label2':tf.FixedLenFeature([],tf.int64),
            'label3':tf.FixedLenFeature([],tf.int64),
        }
    )

    #将字符串解析成对应的像素矩阵
    images = tf.decode_raw(features['image_data'],tf.uint8)
    images = tf.reshape(images,[224,224])
    images = tf.cast(images,tf.float32) / 255.0
    images = tf.subtract(images,0.5)
    images = tf.multiply(images,2.0)

    label0 = tf.cast(features['label0'],tf.int32)
    label1 = tf.cast(features['label1'], tf.int32)
    label2 = tf.cast(features['label2'], tf.int32)
    label3 = tf.cast(features['label3'], tf.int32)

    return images,label0,label1,label2,label3

image,label0,label1,label2,label3 = read_and_decode(TFRECORD_DIR)

#读取一个batch大小的数据
image_batch,label0_batch,label1_batch,label2_batch,label3_batch = tf.train.shuffle_batch([image,label0,label1,label2,label3],
                                                                                         batch_size=BATCH_SIZE,
                                                                                         capacity=50000,
                                                                                         min_after_dequeue=10000,
                                                                                         num_threads=1)

with tf.Session() as sess:

    X = tf.reshape(x,[BATCH_SIZE,224,224,1])

    #一次学习出来四个目标
    logit0,logit1,logit2,logit3 = AlexNet_Mulity.inference(X,'train',None)

    #将实际的标签转化为需要的形式
    one_hot_label0 = tf.one_hot(indices=tf.cast(y0,tf.int32),depth=NUM_CLASS)
    one_hot_label1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=NUM_CLASS)
    one_hot_label2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=NUM_CLASS)
    one_hot_label3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=NUM_CLASS)

    #计算损失
    loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit0,labels=one_hot_label0))
    loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit1, labels=one_hot_label1))
    loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit2, labels=one_hot_label2))
    loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit3, labels=one_hot_label3))

    #计算总的损失
    total_loss = (loss0 + loss1 + loss2 + loss3) / 4.0

    train_step = tf.train.AdamOptimizer(0.001).minimize(total_loss)

    #计算正确率
    correct_prediction0 = tf.equal(tf.argmax(logit0,1),tf.argmax(one_hot_label0,1))
    accurancy0 = tf.reduce_mean(tf.cast(correct_prediction0,tf.float32))

    correct_prediction1 = tf.equal(tf.argmax(logit1, 1), tf.argmax(one_hot_label1, 1))
    accurancy1 = tf.reduce_mean(tf.cast(correct_prediction1, tf.float32))

    correct_prediction2 = tf.equal(tf.argmax(logit2, 1), tf.argmax(one_hot_label2, 1))
    accurancy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))

    correct_prediction3 = tf.equal(tf.argmax(logit3, 1), tf.argmax(one_hot_label3, 1))
    accurancy3 = tf.reduce_mean(tf.cast(correct_prediction3, tf.float32))

    saver = tf.train.Saver()
    sess.run(tf.global_variables_initializer())

    #创建队列管理器
    coor = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess,coord=coor)

    for i in range(6000):

        b_image,b_label0,b_label1,b_label2,b_label3 = sess.run([image_batch,label0_batch,label1_batch,label2_batch,label3_batch])
        sess.run(train_step,feed_dict={x:b_image,y0:b_label0,y1:b_label1,y2:b_label2,y3:b_label3})

        if i % 20 == 0:

            acc0,acc1,acc2,acc3,loss = sess.run([accurancy0,accurancy1,accurancy2,accurancy3,total_loss],feed_dict={x:b_image,y0:b_label0,y1:b_label1,y2:b_label2,y3:b_label3})
            print('Iter:%d Loss:%.3f Accurancy:%.2f,%.2f,%.2f,%.2f'%(i,loss,acc0,acc1,acc2,acc3))
            saver.save(sess,'model\model.ckpt',global_step=i)

    coor.request_stop()
    coor.join(threads)
